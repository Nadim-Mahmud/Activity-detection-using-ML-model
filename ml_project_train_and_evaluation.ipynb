{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218aeb79",
   "metadata": {},
   "source": [
    "## Predication with Different Classification Method to The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cecb0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Ensemble Methods\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df5f1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b276802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(obj, p, cycle)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set max output lines before scrolling\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.instance().display_formatter.formatters['text/plain'].for_type(\n",
    "    type, lambda obj, p, cycle: p.text(repr(obj)[:10000])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db941cad",
   "metadata": {},
   "source": [
    "### Metrics Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1aceecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric Calculations\n",
    "\n",
    "def calculate_metrics(classifier, y_val, y_pred):\n",
    "    print(f\"{classifier} metrics: \")\n",
    "\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9677b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_accuracy_gen(model, label, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    calculate_metrics(label, y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a91ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluationPipeline:\n",
    "\n",
    "    param_grid_logistic_regression = {\n",
    "        'C': [0.01, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "        'penalty': ['l2'],\n",
    "        'max_iter': [100, 500, 1000]\n",
    "    }\n",
    "\n",
    "    param_grid_decission_tree_classifier = {\n",
    "        'max_depth': [None, 5, 20, 50],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    }\n",
    "\n",
    "    param_grid_random_forest_classifier = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20, 50],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_gaussian_naive_bias = {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "    }\n",
    "\n",
    "    param_grid_svc = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': [100, 500, 700, 900, 1100, 1500],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['minkowski'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    param_grid_ada_boost = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.5, 1.0],\n",
    "        'estimator': [\n",
    "            DecisionTreeClassifier(max_depth=1),\n",
    "            DecisionTreeClassifier(max_depth=3)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2], \n",
    "        'subsample': [0.6, 0.8, 1.0],     \n",
    "        'gamma': [0, 0.1, 0.3, 0.5],           \n",
    "    }\n",
    "\n",
    "    param_grid_grad_boost = {\n",
    "      'n_estimators': [50],\n",
    "      'learning_rate': [0.01, 0.1],\n",
    "      'max_depth': [3, 5],\n",
    "      'random_state': [42]\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'model__n_neurons': [64],\n",
    "        'model__activation': ['relu', 'tanh'],\n",
    "        'epochs': [100, 150],\n",
    "        'batch_size': [50, 100]\n",
    "    }\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.feature_path = file_path\n",
    "        self.feature_df = self.get_feture()\n",
    "        self.X, self.y = self.split_feture_and_target()\n",
    "        self.y = self.map_zero_to_n() # mapping y zero to number of class to make it usable for some modles i.e. xgaboost\n",
    "        self.numer_of_categories = self.get_number_of_categories()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.get_scale_and_test_train_split()\n",
    "\n",
    "    # data read and processing section\n",
    "    def remove_outliear(self, feature_df):\n",
    "        iso = IsolationForest(contamination=0.01, random_state=42)\n",
    "        outliers = iso.fit_predict(feature_df)\n",
    "        data_cleaned = feature_df[outliers == 1]\n",
    "\n",
    "        return data_cleaned\n",
    "\n",
    "    def get_feture(self):\n",
    "        feature_df = pd.read_csv(self.feature_path)\n",
    "        feature_df = feature_df.iloc[:, 1:] # remove index\n",
    "        \n",
    "        return self.remove_outliear(feature_df)\n",
    "\n",
    "    def split_feture_and_target(self):\n",
    "        X = self.feature_df.iloc[:, :-1]\n",
    "        y = self.feature_df.iloc[:, -1]\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def get_scale_and_test_train_split(self):\n",
    "        #Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_fature = scaler.fit_transform(self.X)\n",
    "        \n",
    "        #test train split\n",
    "        return train_test_split(scaled_fature, self.y, train_size=.20, random_state=42, stratify=self.y)\n",
    "    \n",
    "    def map_zero_to_n(self):\n",
    "        unique_values = {val: idx for idx, val in enumerate(self.y.unique())}\n",
    "        y_mapped = self.y.map(unique_values)\n",
    "\n",
    "        return y_mapped\n",
    "    \n",
    "    def get_number_of_categories(self):\n",
    "        return len(self.y.unique())\n",
    "\n",
    "    def onehot_encode(self):\n",
    "        self.y_train = to_categorical(self.y_train, num_classes = self.number_of_categories)\n",
    "    \n",
    "    # Cross validation section \n",
    "    def kfold_cross_validation(self, model, n_splits):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        kfold_score = cross_val_score(model, self.X, self.y, cv=kf)\n",
    "\n",
    "        print(\"K-fold cross validaiton scores:\", kfold_score)\n",
    "        print(\"Average score:\", np.mean(kfold_score))\n",
    "\n",
    "\n",
    "    def stratified_cross_validation(self, model, n_splits):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        skfold_score = cross_val_score(model, self.X, self.y, cv=skf)\n",
    "\n",
    "        print(\"Straified cross validation scores:\", skfold_score)\n",
    "        print(\"Average score:\", np.mean(skfold_score))\n",
    "\n",
    "\n",
    "    def cross_validation(self, model, n_splits):\n",
    "        self.kfold_cross_validation(model, n_splits)\n",
    "        self.stratified_cross_validation(model, n_splits)\n",
    "\n",
    "    # Hyper parameter tuning\n",
    "\n",
    "    def gridSerach(self, estimator, param_grid):\n",
    "        print(\"==== Grid Search: =====\")\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3, verbose=0)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters found: \", grid_search.best_params_)\n",
    "        print(\"Best score found: \", grid_search.best_score_)\n",
    "\n",
    "        return grid_search\n",
    "    \n",
    "    def randomSearch(self, estimator, param_grid):\n",
    "        print(\"\\n==== Random Search: =====\")\n",
    "\n",
    "        random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=500, cv=3, random_state=42)\n",
    "        random_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(\"Best parameters found: \", random_search.best_params_)\n",
    "        print(\"Best score found: \", random_search.best_score_)\n",
    "\n",
    "        return random_search\n",
    "    \n",
    "    def hyper_parameter_tuning(self, model, param_grid):\n",
    "        grid_search = self.gridSerach(model, param_grid)\n",
    "        random_search = self.randomSearch(model, param_grid)\n",
    "\n",
    "        return grid_search if grid_search.best_score_ > random_search.best_score_ else random_search\n",
    "    \n",
    "    # Models section\n",
    "    def run_logistic_regression_model(self):\n",
    "        print(\"=============== 1. Logistic Regression Section: ==================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(LogisticRegression(), self.param_grid_logistic_regression)\n",
    "        lrm = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(lrm, \"1. Logistic regression\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(lrm, 10)\n",
    "    \n",
    "    def run_decission_tree_classifier_model(self):\n",
    "        print(\"=================2. Decission Tree Classifier Section: ================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(DecisionTreeClassifier(), self.param_grid_decission_tree_classifier)\n",
    "        dt = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(dt, \"2. Decission Tree Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(dt, 10)\n",
    "\n",
    "    def run_random_forest_classifier_model(self):\n",
    "        print(\"=================== 3. Random Forest Classifier Section: ==================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(RandomForestClassifier(), self.param_grid_random_forest_classifier)\n",
    "        rfc = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(rfc, \"3.  Random Forest Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(rfc, 10)\n",
    "\n",
    "    def run_gaussian_naive_bias_classifier_model(self):\n",
    "        print(\"=================== 4. Gaussian Naive Bias Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GaussianNB(), self.param_grid_gaussian_naive_bias)\n",
    "        gnb = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(gnb, \"4. Gaussian Naive Bias Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gnb, 10)\n",
    "\n",
    "\n",
    "    def run_support_vector_classifier_model(self):\n",
    "        print(\"=================== 5. Support Vector Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(SVC(), self.param_grid_svc)\n",
    "        svc = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(svc, \"5. Support Vector Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(svc, 10)\n",
    "\n",
    "\n",
    "    def run_knn_classifier_model(self):\n",
    "        print(\"=================== 6. K-Nearest Neighbors Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(KNeighborsClassifier(), self.param_grid_knn)\n",
    "        knn = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(knn, \"6. K-Nearest Neighbors\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(knn, 10)\n",
    "\n",
    "    def run_ada_boost_classifier_model(self):\n",
    "        print(\"=================== 7. Ada Boost Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(AdaBoostClassifier(), self.param_grid_ada_boost)\n",
    "        abc = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(abc, \"7. Ada Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(abc, 10)\n",
    "\n",
    "    def run_xg_boost_classifier_model(self):\n",
    "        print(\"=================== 8. XG Boost Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(XGBClassifier(), self.param_grid_xgb)\n",
    "        xgb = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(xgb, \"8. XG Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(xgb, 10)\n",
    "\n",
    "    def run_gradient_boost_classifier_model(self):\n",
    "        print(\"=================== 9. Gradient Boost Classifier Section: ===================\")\n",
    "\n",
    "        tuned_model = self.hyper_parameter_tuning(GradientBoostingClassifier(), self.param_grid_grad_boost)\n",
    "        gb = tuned_model.best_estimator_\n",
    "\n",
    "        train_and_accuracy_gen(gb, \"9. Gradient Boost Classifier\", self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "        self.cross_validation(gb, 5)\n",
    "\n",
    "    # ANN section\n",
    "    def ann_kfold_cross_validation(self, model, n_splits=2, epochs=50, batch_size=100):\n",
    "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "      scores = []\n",
    "\n",
    "      X = self.X\n",
    "      y = self.y\n",
    "      for train_index, val_index in kf.split(X):\n",
    "          X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "          y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "          y_train = to_categorical(y_train, num_classes=self.number_of_categories)\n",
    "\n",
    "          model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "          # Evaluate the model\n",
    "          y_val_pred = np.argmax(model.predict(X_val), axis=1)  # Convert probabilities to class labels\n",
    "          accuracy = accuracy_score(y_val, y_val_pred)\n",
    "          scores.append(accuracy)\n",
    "\n",
    "      print(\"K-fold cross-validation scores:\", scores)\n",
    "      print(\"Average score:\", np.mean(scores))\n",
    "\n",
    "    def ann_stratified_cross_validation(self, model, n_splits=2, epochs=50, batch_size=100):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "\n",
    "        for train_index, val_index in skf.split(self.X, self.y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            y_train = to_categorical(y_train, num_classes=self.number_of_categories)\n",
    "\n",
    "            model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_val_pred = np.argmax(model.predict(X_val), axis=1)  # Convert probabilities to class labels\n",
    "            accuracy = accuracy_score(y_val, y_val_pred)\n",
    "            scores.append(accuracy)\n",
    "\n",
    "        print(\"Stratified cross-validation scores:\", scores)\n",
    "        print(\"Average score:\", np.mean(scores))\n",
    "\n",
    "    def ann_cross_validation(self, model, n_splits=2, epochs=50, batch_size=100):\n",
    "        self.ann_kfold_cross_validation(model, n_splits, epochs, batch_size)\n",
    "        self.ann_stratified_cross_validation(model, n_splits, epochs, batch_size) \n",
    "\n",
    "    @staticmethod\n",
    "    def build_ann(n_neurons=128, activation='relu'):\n",
    "        model = Sequential()\n",
    "        # Input layer\n",
    "        model.add(Dense(n_neurons, activation=activation, input_shape=(24,)))\n",
    "        \n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "        model.add(Dense(n_neurons, activation=activation))\n",
    "            \n",
    "        # Output layer (example for binary classification)\n",
    "        model.add(Dense(units=3, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def run_ann_model(self):\n",
    "        print(\"=================== 10. Artificial Neural Net Section: ===================\")\n",
    "\n",
    "        y_train_tmp = self.y_train\n",
    "\n",
    "        self.onehot_encode()\n",
    "\n",
    "        model = KerasClassifier(build_fn=self.build_ann, verbose=0, epochs = 50, batch_size = 100)\n",
    "        \n",
    "        tuned_model = self.hyper_parameter_tuning(model, self.param_grid_ann)\n",
    "        ann = tuned_model.best_estimator_\n",
    "\n",
    "        ann.fit(self.X_train, self.y_train)\n",
    "        y_pred = ann.predict(self.X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        calculate_metrics(\"10. Artificial Neuralnet\", self.y_test, y_pred_classes)\n",
    "        self.ann_cross_validation(ann)\n",
    "\n",
    "        self.y_train = y_train_tmp\n",
    "\n",
    "    def driver(self):\n",
    "        self.run_logistic_regression_model()\n",
    "        self.run_decission_tree_classifier_model()\n",
    "        self.run_random_forest_classifier_model()\n",
    "        self.run_gaussian_naive_bias_classifier_model()\n",
    "        self.run_support_vector_classifier_model()\n",
    "        self.run_knn_classifier_model()\n",
    "        self.run_ada_boost_classifier_model()\n",
    "        self.run_xg_boost_classifier_model()\n",
    "        # self.run_ann_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772b588",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 100 & 25% Overlap ==\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57df36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1. Logistic Regression Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score found:  0.30028598976074977\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "Best score found:  0.30028598976074977\n",
      "1. Logistic regression metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.41      0.37      2113\n",
      "           1       0.21      0.21      0.21      2267\n",
      "           2       0.14      0.16      0.15      2174\n",
      "           3       0.23      0.35      0.27      2224\n",
      "           4       0.91      0.74      0.81      1721\n",
      "           5       0.16      0.13      0.14      2222\n",
      "           6       0.12      0.01      0.02      2133\n",
      "           7       0.36      0.03      0.05      1649\n",
      "           8       0.60      0.71      0.65      1982\n",
      "           9       0.20      0.25      0.22      2113\n",
      "          10       0.15      0.06      0.09      1788\n",
      "          11       0.23      0.07      0.11      2081\n",
      "          12       0.22      0.29      0.25      2278\n",
      "          13       0.18      0.38      0.24      2161\n",
      "          14       0.59      0.80      0.68      1800\n",
      "\n",
      "    accuracy                           0.30     30706\n",
      "   macro avg       0.31      0.31      0.29     30706\n",
      "weighted avg       0.30      0.30      0.28     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.2453764  0.22193279 0.263679   0.27670662 0.2582074  0.24361647\n",
      " 0.26680563 0.23658155 0.26498176 0.24570089]\n",
      "Straified cross validation scores: [0.25188851 0.24329252 0.25429911 0.26654508 0.26993226 0.25951016\n",
      " 0.25039083 0.2522147  0.24335591 0.26341845]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline = ModelEvaluationPipeline(\"features/w100_o25_features.csv\")\n",
    "w100_o25_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86aeece5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================2. Decission Tree Classifier Section: ================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5}\n",
      "Best score found:  0.5052100121775562\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 10, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best score found:  0.504296924609449\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.34      0.32      2113\n",
      "           1       0.46      0.47      0.46      2267\n",
      "           2       0.41      0.43      0.42      2174\n",
      "           3       0.51      0.59      0.54      2224\n",
      "           4       0.79      0.82      0.80      1721\n",
      "           5       0.37      0.40      0.39      2222\n",
      "           6       0.39      0.38      0.38      2133\n",
      "           7       0.34      0.33      0.34      1649\n",
      "           8       0.65      0.66      0.66      1982\n",
      "           9       0.81      0.79      0.80      2113\n",
      "          10       0.40      0.40      0.40      1788\n",
      "          11       0.26      0.24      0.25      2081\n",
      "          12       0.61      0.52      0.56      2278\n",
      "          13       0.72      0.66      0.69      2161\n",
      "          14       0.70      0.66      0.68      1800\n",
      "\n",
      "    accuracy                           0.51     30706\n",
      "   macro avg       0.52      0.51      0.51     30706\n",
      "weighted avg       0.51      0.51      0.51     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.60901276 0.59911435 0.60135487 0.59431996 0.60630537 0.59718603\n",
      " 0.60604482 0.59927045 0.59927045 0.60317874]\n",
      "Straified cross validation scores: [0.60302162 0.60302162 0.60786868 0.59927045 0.60083377 0.59536217\n",
      " 0.59588327 0.61933299 0.61021365 0.59588327]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8436278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 3. Random Forest Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 500}\n",
      "Best score found:  0.6263648828486906\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 500, 'max_depth': 20, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score found:  0.625974105201172\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.60      0.49      2113\n",
      "           1       0.61      0.66      0.63      2267\n",
      "           2       0.68      0.47      0.56      2174\n",
      "           3       0.65      0.74      0.69      2224\n",
      "           4       0.91      0.85      0.88      1721\n",
      "           5       0.50      0.56      0.53      2222\n",
      "           6       0.66      0.42      0.51      2133\n",
      "           7       0.56      0.43      0.48      1649\n",
      "           8       0.67      0.83      0.74      1982\n",
      "           9       0.85      0.90      0.87      2113\n",
      "          10       0.57      0.52      0.54      1788\n",
      "          11       0.44      0.30      0.36      2081\n",
      "          12       0.70      0.70      0.70      2278\n",
      "          13       0.76      0.81      0.78      2161\n",
      "          14       0.71      0.84      0.77      1800\n",
      "\n",
      "    accuracy                           0.64     30706\n",
      "   macro avg       0.65      0.64      0.64     30706\n",
      "weighted avg       0.64      0.64      0.64     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.72701224 0.72154207 0.72668056 0.71521626 0.72146952 0.71599792\n",
      " 0.73163106 0.7199062  0.73397603 0.7193851 ]\n",
      "Straified cross validation scores: [0.71971868 0.72050013 0.72120896 0.72329338 0.72303283 0.73137051\n",
      " 0.72954664 0.71860344 0.72589891 0.72068786]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "392cc94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 0.0001}\n",
      "Best score found:  0.22420539077611987\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 0.0001}\n",
      "Best score found:  0.22420539077611987\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18      2113\n",
      "           1       0.23      0.14      0.17      2267\n",
      "           2       0.10      0.01      0.01      2174\n",
      "           3       0.17      0.01      0.03      2224\n",
      "           4       0.83      0.72      0.77      1721\n",
      "           5       0.13      0.08      0.10      2222\n",
      "           6       0.13      0.01      0.03      2133\n",
      "           7       0.12      0.03      0.04      1649\n",
      "           8       0.47      0.58      0.52      1982\n",
      "           9       0.13      0.03      0.04      2113\n",
      "          10       0.12      0.05      0.07      1788\n",
      "          11       0.17      0.07      0.10      2081\n",
      "          12       0.13      0.09      0.11      2278\n",
      "          13       0.12      0.89      0.21      2161\n",
      "          14       0.54      0.63      0.58      1800\n",
      "\n",
      "    accuracy                           0.22     30706\n",
      "   macro avg       0.24      0.23      0.20     30706\n",
      "weighted avg       0.23      0.22      0.19     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.13076322 0.12763741 0.13288171 0.13079729 0.1378322  0.12949453\n",
      " 0.12272017 0.13574779 0.13288171 0.12662845]\n",
      "Straified cross validation scores: [0.13180516 0.12998177 0.13157895 0.126889   0.13288171 0.12897342\n",
      " 0.13548723 0.12819177 0.12819177 0.13340281]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99a0c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.5385602924487439\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score found:  0.5385602924487439\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.47      0.40      2113\n",
      "           1       0.56      0.57      0.56      2267\n",
      "           2       0.40      0.45      0.43      2174\n",
      "           3       0.56      0.68      0.61      2224\n",
      "           4       0.84      0.83      0.84      1721\n",
      "           5       0.45      0.43      0.44      2222\n",
      "           6       0.37      0.28      0.32      2133\n",
      "           7       0.43      0.34      0.38      1649\n",
      "           8       0.57      0.79      0.66      1982\n",
      "           9       0.80      0.83      0.81      2113\n",
      "          10       0.53      0.41      0.46      1788\n",
      "          11       0.35      0.24      0.29      2081\n",
      "          12       0.62      0.58      0.60      2278\n",
      "          13       0.77      0.71      0.74      2161\n",
      "          14       0.73      0.75      0.74      1800\n",
      "\n",
      "    accuracy                           0.56     30706\n",
      "   macro avg       0.56      0.56      0.55     30706\n",
      "weighted avg       0.55      0.56      0.55     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.26855952 0.27142485 0.28452319 0.27696717 0.27774883 0.27540386\n",
      " 0.27853048 0.28217822 0.27618551 0.26550287]\n",
      "Straified cross validation scores: [0.27142485 0.27142485 0.28295987 0.28191767 0.27696717 0.27774883\n",
      " 0.27488275 0.26628452 0.27331944 0.26862949]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8578ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 6. K-Nearest Neighbors Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score found:  0.5031243370554471\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score found:  0.5031243370554471\n",
      "6. K-Nearest Neighbors metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.28      0.32      2113\n",
      "           1       0.58      0.49      0.53      2267\n",
      "           2       0.60      0.43      0.50      2174\n",
      "           3       0.47      0.74      0.57      2224\n",
      "           4       0.91      0.74      0.81      1721\n",
      "           5       0.34      0.45      0.39      2222\n",
      "           6       0.72      0.34      0.46      2133\n",
      "           7       0.48      0.25      0.33      1649\n",
      "           8       0.55      0.65      0.59      1982\n",
      "           9       0.66      0.84      0.74      2113\n",
      "          10       0.52      0.30      0.38      1788\n",
      "          11       0.38      0.16      0.23      2081\n",
      "          12       0.45      0.72      0.55      2278\n",
      "          13       0.60      0.61      0.61      2161\n",
      "          14       0.47      0.85      0.61      1800\n",
      "\n",
      "    accuracy                           0.52     30706\n",
      "   macro avg       0.54      0.52      0.51     30706\n",
      "weighted avg       0.54      0.52      0.51     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.36207346 0.35712425 0.373111   0.36425221 0.36868161 0.35617509\n",
      " 0.36842105 0.35982282 0.37623762 0.34445023]\n",
      "Straified cross validation scores: [0.3714509  0.35399844 0.36008338 0.37571652 0.36529442 0.36190724\n",
      " 0.3681605  0.36008338 0.36034393 0.3741532 ]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5360ffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 7. Ada Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best score found:  0.3444527244086726\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 100, 'learning_rate': 0.01, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score found:  0.3444527244086726\n",
      "7. Ada Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.62      0.37      2113\n",
      "           1       0.30      0.44      0.35      2267\n",
      "           2       0.57      0.03      0.06      2174\n",
      "           3       0.23      0.29      0.26      2224\n",
      "           4       0.00      0.00      0.00      1721\n",
      "           5       0.18      0.20      0.19      2222\n",
      "           6       0.23      0.00      0.00      2133\n",
      "           7       0.35      0.10      0.15      1649\n",
      "           8       0.38      0.76      0.51      1982\n",
      "           9       0.62      0.37      0.46      2113\n",
      "          10       0.23      0.04      0.06      1788\n",
      "          11       0.15      0.02      0.03      2081\n",
      "          12       0.22      0.63      0.33      2278\n",
      "          13       0.39      0.42      0.40      2161\n",
      "          14       0.64      0.75      0.69      1800\n",
      "\n",
      "    accuracy                           0.32     30706\n",
      "   macro avg       0.32      0.31      0.26     30706\n",
      "weighted avg       0.32      0.32      0.26     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.31388382 0.32352175 0.33090151 0.31605003 0.32595102 0.3238666\n",
      " 0.32647212 0.32490881 0.33324648 0.3238666 ]\n",
      "Straified cross validation scores: [0.32560563 0.32378223 0.3293382  0.31969776 0.32647212 0.32021886\n",
      " 0.3243877  0.31474726 0.33090151 0.31813445]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89859406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 8. XG Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'gamma': 0, 'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best score found:  0.6232385598239637\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'subsample': 0.8, 'n_estimators': 200, 'learning_rate': 0.2, 'gamma': 0}\n",
      "Best score found:  0.6232385598239637\n",
      "8. XG Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50      2113\n",
      "           1       0.63      0.64      0.63      2267\n",
      "           2       0.65      0.52      0.58      2174\n",
      "           3       0.65      0.72      0.68      2224\n",
      "           4       0.91      0.85      0.88      1721\n",
      "           5       0.47      0.53      0.50      2222\n",
      "           6       0.60      0.46      0.52      2133\n",
      "           7       0.51      0.41      0.45      1649\n",
      "           8       0.74      0.82      0.78      1982\n",
      "           9       0.85      0.89      0.87      2113\n",
      "          10       0.55      0.52      0.54      1788\n",
      "          11       0.38      0.35      0.37      2081\n",
      "          12       0.69      0.68      0.68      2278\n",
      "          13       0.76      0.81      0.78      2161\n",
      "          14       0.76      0.85      0.80      1800\n",
      "\n",
      "    accuracy                           0.64     30706\n",
      "   macro avg       0.64      0.64      0.64     30706\n",
      "weighted avg       0.64      0.64      0.64     30706\n",
      "\n",
      "K-fold cross validaiton scores: [0.72987757 0.72180255 0.70948411 0.71365294 0.72199062 0.71313184\n",
      " 0.72720167 0.71417405 0.72511725 0.71365294]\n",
      "Straified cross validation scores: [0.70773639 0.71711383 0.70922355 0.71313184 0.71287129 0.72746222\n",
      " 0.71756123 0.71912454 0.72277228 0.71261073]\n"
     ]
    }
   ],
   "source": [
    "w100_o25_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dea4b3",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 100 & 50% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76401191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1. Logistic Regression Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score found:  0.2812825860271116\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "Best score found:  0.2812825860271116\n",
      "1. Logistic regression metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.40      0.36      3172\n",
      "           1       0.22      0.22      0.22      3402\n",
      "           2       0.11      0.09      0.10      3254\n",
      "           3       0.20      0.38      0.26      3333\n",
      "           4       0.93      0.75      0.83      2557\n",
      "           5       0.16      0.12      0.14      3332\n",
      "           6       0.17      0.01      0.02      3208\n",
      "           7       0.32      0.01      0.02      2466\n",
      "           8       0.62      0.72      0.66      2984\n",
      "           9       0.16      0.13      0.15      3168\n",
      "          10       0.15      0.05      0.07      2681\n",
      "          11       0.27      0.10      0.14      3122\n",
      "          12       0.19      0.27      0.22      3415\n",
      "          13       0.16      0.39      0.23      3241\n",
      "          14       0.59      0.80      0.68      2697\n",
      "\n",
      "    accuracy                           0.29     46032\n",
      "   macro avg       0.30      0.30      0.27     46032\n",
      "weighted avg       0.29      0.29      0.26     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.2455683  0.25147723 0.23792145 0.23305527 0.25530066 0.25147723\n",
      " 0.25182482 0.23409802 0.26659715 0.256691  ]\n",
      "Straified cross validation scores: [0.25981926 0.24921794 0.21724018 0.24730622 0.24209246 0.24139729\n",
      " 0.23583594 0.25477928 0.20611748 0.25321515]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline = ModelEvaluationPipeline(\"features/w100_o50_features.csv\")\n",
    "w100_o50_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32154551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================2. Decission Tree Classifier Section: ================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 20}\n",
      "Best score found:  0.5251129648939868\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 20, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Best score found:  0.5264164059784499\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.42      0.40      3172\n",
      "           1       0.46      0.55      0.50      3402\n",
      "           2       0.47      0.42      0.45      3254\n",
      "           3       0.60      0.62      0.61      3333\n",
      "           4       0.80      0.80      0.80      2557\n",
      "           5       0.38      0.48      0.42      3332\n",
      "           6       0.48      0.41      0.44      3208\n",
      "           7       0.39      0.35      0.37      2466\n",
      "           8       0.61      0.65      0.63      2984\n",
      "           9       0.78      0.79      0.79      3168\n",
      "          10       0.44      0.42      0.43      2681\n",
      "          11       0.28      0.25      0.27      3122\n",
      "          12       0.58      0.56      0.57      3415\n",
      "          13       0.72      0.65      0.68      3241\n",
      "          14       0.74      0.67      0.70      2697\n",
      "\n",
      "    accuracy                           0.53     46032\n",
      "   macro avg       0.54      0.54      0.54     46032\n",
      "weighted avg       0.54      0.53      0.54     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.62634689 0.63017032 0.62443518 0.61696211 0.63347237 0.6261731\n",
      " 0.62530414 0.62043796 0.62547793 0.62026416]\n",
      "Straified cross validation scores: [0.63955509 0.61609315 0.62547793 0.63607925 0.62843239 0.63017032\n",
      " 0.6173097  0.62565172 0.6150504  0.62356621]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "138ae675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 3. Random Forest Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 500}\n",
      "Best score found:  0.6624087591240876\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 500, 'max_depth': 50, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score found:  0.6632777198470629\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.51      3172\n",
      "           1       0.63      0.73      0.67      3402\n",
      "           2       0.76      0.54      0.63      3254\n",
      "           3       0.73      0.76      0.75      3333\n",
      "           4       0.92      0.88      0.90      2557\n",
      "           5       0.56      0.61      0.59      3332\n",
      "           6       0.73      0.47      0.57      3208\n",
      "           7       0.60      0.49      0.54      2466\n",
      "           8       0.70      0.84      0.76      2984\n",
      "           9       0.87      0.91      0.89      3168\n",
      "          10       0.65      0.58      0.61      2681\n",
      "          11       0.53      0.37      0.44      3122\n",
      "          12       0.71      0.78      0.74      3415\n",
      "          13       0.77      0.82      0.79      3241\n",
      "          14       0.75      0.84      0.79      2697\n",
      "\n",
      "    accuracy                           0.68     46032\n",
      "   macro avg       0.69      0.68      0.68     46032\n",
      "weighted avg       0.69      0.68      0.68     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.77024678 0.76572819 0.76451164 0.75773375 0.77163712 0.76850886\n",
      " 0.76520681 0.76694473 0.76711853 0.76138339]\n",
      "Straified cross validation scores: [0.77754605 0.76451164 0.76711853 0.76729232 0.756691   0.76485923\n",
      " 0.76468544 0.76624957 0.77042058 0.76885645]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e01462d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 0.0001}\n",
      "Best score found:  0.24991310392770247\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 0.0001}\n",
      "Best score found:  0.24991310392770247\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.16      0.21      3172\n",
      "           1       0.23      0.13      0.16      3402\n",
      "           2       0.22      0.02      0.03      3254\n",
      "           3       0.19      0.55      0.28      3333\n",
      "           4       0.85      0.73      0.78      2557\n",
      "           5       0.13      0.09      0.10      3332\n",
      "           6       0.21      0.02      0.03      3208\n",
      "           7       0.09      0.03      0.04      2466\n",
      "           8       0.49      0.59      0.53      2984\n",
      "           9       0.18      0.02      0.04      3168\n",
      "          10       0.11      0.06      0.07      2681\n",
      "          11       0.19      0.05      0.08      3122\n",
      "          12       0.11      0.10      0.11      3415\n",
      "          13       0.18      0.80      0.29      3241\n",
      "          14       0.60      0.65      0.62      2697\n",
      "\n",
      "    accuracy                           0.26     46032\n",
      "   macro avg       0.27      0.27      0.23     46032\n",
      "weighted avg       0.26      0.26      0.22     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.12895377 0.13468891 0.1216545  0.13103928 0.12182829 0.12652068\n",
      " 0.13069169 0.1282586  0.13312478 0.12339242]\n",
      "Straified cross validation scores: [0.12721585 0.12356621 0.1282586  0.12252346 0.12964894 0.1348627\n",
      " 0.12912756 0.12252346 0.12547793 0.13416754]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b3ed267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.5652589502954467\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score found:  0.5652589502954467\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.48      0.42      3172\n",
      "           1       0.59      0.60      0.60      3402\n",
      "           2       0.41      0.39      0.40      3254\n",
      "           3       0.59      0.70      0.64      3333\n",
      "           4       0.84      0.83      0.84      2557\n",
      "           5       0.48      0.49      0.49      3332\n",
      "           6       0.39      0.32      0.35      3208\n",
      "           7       0.47      0.40      0.44      2466\n",
      "           8       0.58      0.80      0.67      2984\n",
      "           9       0.79      0.87      0.83      3168\n",
      "          10       0.60      0.44      0.51      2681\n",
      "          11       0.44      0.28      0.34      3122\n",
      "          12       0.60      0.66      0.63      3415\n",
      "          13       0.80      0.70      0.75      3241\n",
      "          14       0.78      0.75      0.76      2697\n",
      "\n",
      "    accuracy                           0.58     46032\n",
      "   macro avg       0.58      0.58      0.58     46032\n",
      "weighted avg       0.58      0.58      0.57     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.28693083 0.29040667 0.29023288 0.28084811 0.29509906 0.30257212\n",
      " 0.30066041 0.29631561 0.29666319 0.30257212]\n",
      "Straified cross validation scores: [0.30344108 0.29075426 0.29127563 0.28849496 0.28571429 0.29509906\n",
      " 0.29127563 0.30709072 0.28745221 0.29075426]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eba9d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 6. K-Nearest Neighbors Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score found:  0.5222453945081682\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score found:  0.5222453945081682\n",
      "6. K-Nearest Neighbors metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.30      0.34      3172\n",
      "           1       0.53      0.52      0.53      3402\n",
      "           2       0.64      0.46      0.53      3254\n",
      "           3       0.49      0.73      0.58      3333\n",
      "           4       0.92      0.77      0.84      2557\n",
      "           5       0.37      0.47      0.41      3332\n",
      "           6       0.73      0.35      0.47      3208\n",
      "           7       0.52      0.27      0.36      2466\n",
      "           8       0.58      0.68      0.63      2984\n",
      "           9       0.68      0.88      0.77      3168\n",
      "          10       0.61      0.37      0.46      2681\n",
      "          11       0.40      0.17      0.24      3122\n",
      "          12       0.48      0.75      0.58      3415\n",
      "          13       0.64      0.64      0.64      3241\n",
      "          14       0.50      0.86      0.64      2697\n",
      "\n",
      "    accuracy                           0.55     46032\n",
      "   macro avg       0.57      0.55      0.53     46032\n",
      "weighted avg       0.56      0.55      0.53     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.37938825 0.37643379 0.37643379 0.36809176 0.38877303 0.3892944\n",
      " 0.37573862 0.38390685 0.37226277 0.36687522]\n",
      "Straified cross validation scores: [0.38112617 0.37678137 0.37069864 0.37782412 0.37087244 0.37799791\n",
      " 0.37330553 0.39363921 0.37208898 0.38338547]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd95f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 7. Ada Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 200}\n",
      "Best score found:  0.3435001737921446\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 200, 'learning_rate': 0.01, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score found:  0.34358706986444215\n",
      "7. Ada Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.61      0.38      3172\n",
      "           1       0.33      0.51      0.40      3402\n",
      "           2       0.50      0.33      0.40      3254\n",
      "           3       0.36      0.27      0.30      3333\n",
      "           4       0.87      0.02      0.04      2557\n",
      "           5       0.17      0.24      0.20      3332\n",
      "           6       0.32      0.01      0.03      3208\n",
      "           7       0.39      0.12      0.18      2466\n",
      "           8       0.38      0.76      0.51      2984\n",
      "           9       0.74      0.13      0.22      3168\n",
      "          10       0.31      0.04      0.07      2681\n",
      "          11       0.25      0.06      0.10      3122\n",
      "          12       0.25      0.56      0.35      3415\n",
      "          13       0.39      0.66      0.49      3241\n",
      "          14       0.67      0.76      0.71      2697\n",
      "\n",
      "    accuracy                           0.35     46032\n",
      "   macro avg       0.42      0.34      0.29     46032\n",
      "weighted avg       0.41      0.35      0.30     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.33872089 0.34914842 0.32898853 0.33715676 0.33750434 0.33107404\n",
      " 0.34480361 0.34202294 0.34688912 0.35505735]\n",
      "Straified cross validation scores: [0.34810567 0.33350713 0.34393465 0.33507125 0.33489746 0.34636774\n",
      " 0.33246437 0.33993743 0.33993743 0.3451512 ]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff81dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 8. XG Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'gamma': 0, 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best score found:  0.651372957942301\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'subsample': 0.8, 'n_estimators': 200, 'learning_rate': 0.1, 'gamma': 0}\n",
      "Best score found:  0.651372957942301\n",
      "8. XG Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.60      0.52      3172\n",
      "           1       0.65      0.70      0.67      3402\n",
      "           2       0.69      0.55      0.61      3254\n",
      "           3       0.69      0.76      0.72      3333\n",
      "           4       0.92      0.89      0.90      2557\n",
      "           5       0.52      0.58      0.55      3332\n",
      "           6       0.68      0.46      0.55      3208\n",
      "           7       0.57      0.49      0.53      2466\n",
      "           8       0.77      0.84      0.80      2984\n",
      "           9       0.85      0.92      0.88      3168\n",
      "          10       0.61      0.57      0.59      2681\n",
      "          11       0.46      0.39      0.42      3122\n",
      "          12       0.71      0.74      0.73      3415\n",
      "          13       0.79      0.81      0.80      3241\n",
      "          14       0.79      0.84      0.81      2697\n",
      "\n",
      "    accuracy                           0.67     46032\n",
      "   macro avg       0.68      0.67      0.67     46032\n",
      "weighted avg       0.68      0.67      0.67     46032\n",
      "\n",
      "K-fold cross validaiton scores: [0.72610358 0.72957942 0.7278415  0.72210636 0.725756   0.72610358\n",
      " 0.7212374  0.73340285 0.72836288 0.72002086]\n",
      "Straified cross validation scores: [0.73305527 0.71984706 0.72818909 0.72766771 0.72419187 0.73409802\n",
      " 0.71949948 0.73392423 0.72175878 0.73131734]\n"
     ]
    }
   ],
   "source": [
    "w100_o50_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685b012",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 200 & 25% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d083c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "w200_o25_pipeline = ModelEvaluationPipeline(\"features/w200_o25_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcf29562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1. Logistic Regression Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 100, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score found:  0.3118171573749667\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 500, 'C': 100}\n",
      "Best score found:  0.3118171573749667\n",
      "1. Logistic regression metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.42      1054\n",
      "           1       0.27      0.20      0.23      1134\n",
      "           2       0.12      0.09      0.10      1074\n",
      "           3       0.18      0.42      0.25      1108\n",
      "           4       0.91      0.73      0.81       867\n",
      "           5       0.18      0.13      0.15      1109\n",
      "           6       0.16      0.02      0.04      1050\n",
      "           7       0.34      0.05      0.09       822\n",
      "           8       0.66      0.68      0.67       996\n",
      "           9       0.14      0.14      0.14      1053\n",
      "          10       0.19      0.08      0.11       892\n",
      "          11       0.32      0.19      0.24      1038\n",
      "          12       0.27      0.33      0.29      1135\n",
      "          13       0.19      0.41      0.26      1078\n",
      "          14       0.59      0.82      0.68       897\n",
      "\n",
      "    accuracy                           0.31     15307\n",
      "   macro avg       0.33      0.32      0.30     15307\n",
      "weighted avg       0.31      0.31      0.29     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.18181818 0.17450366 0.16196447 0.1709357  0.1615264  0.17250392\n",
      " 0.1855724  0.18975431 0.17773131 0.17302666]\n",
      "Straified cross validation scores: [0.18129572 0.16509927 0.17502612 0.18243596 0.17616309 0.1589127\n",
      " 0.1735494  0.18243596 0.16989022 0.18086775]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c1fa735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 3. Random Forest Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 200}\n",
      "Best score found:  0.6040225787284611\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 200, 'max_depth': 50, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score found:  0.6053301780482307\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.64      0.53      1054\n",
      "           1       0.57      0.67      0.62      1134\n",
      "           2       0.57      0.40      0.47      1074\n",
      "           3       0.68      0.69      0.68      1108\n",
      "           4       0.96      0.87      0.91       867\n",
      "           5       0.51      0.51      0.51      1109\n",
      "           6       0.57      0.35      0.43      1050\n",
      "           7       0.52      0.40      0.45       822\n",
      "           8       0.71      0.85      0.77       996\n",
      "           9       0.84      0.90      0.87      1053\n",
      "          10       0.55      0.42      0.47       892\n",
      "          11       0.42      0.38      0.40      1038\n",
      "          12       0.65      0.73      0.69      1135\n",
      "          13       0.77      0.80      0.79      1078\n",
      "          14       0.71      0.87      0.78       897\n",
      "\n",
      "    accuracy                           0.63     15307\n",
      "   macro avg       0.63      0.63      0.63     15307\n",
      "weighted avg       0.63      0.63      0.62     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.71107628 0.7507837  0.70950888 0.72347099 0.69681129 0.72974386\n",
      " 0.72556194 0.72922112 0.71719812 0.71510716]\n",
      "Straified cross validation scores: [0.7460815  0.73301985 0.71577847 0.70778881 0.72033455 0.70151594\n",
      " 0.71510716 0.7156299  0.71876634 0.73131208]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f35d72a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================2. Decission Tree Classifier Section: ================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10}\n",
      "Best score found:  0.4712446985063618\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 10, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "Best score found:  0.4670625115249862\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33      1054\n",
      "           1       0.41      0.46      0.43      1134\n",
      "           2       0.27      0.34      0.30      1074\n",
      "           3       0.49      0.54      0.51      1108\n",
      "           4       0.81      0.80      0.81       867\n",
      "           5       0.38      0.36      0.37      1109\n",
      "           6       0.29      0.32      0.30      1050\n",
      "           7       0.27      0.27      0.27       822\n",
      "           8       0.69      0.63      0.66       996\n",
      "           9       0.73      0.72      0.72      1053\n",
      "          10       0.29      0.28      0.28       892\n",
      "          11       0.24      0.22      0.23      1038\n",
      "          12       0.68      0.51      0.58      1135\n",
      "          13       0.62      0.59      0.60      1078\n",
      "          14       0.66      0.65      0.65       897\n",
      "\n",
      "    accuracy                           0.47     15307\n",
      "   macro avg       0.48      0.47      0.47     15307\n",
      "weighted avg       0.48      0.47      0.47     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.59090909 0.62904911 0.5799373  0.58389963 0.5781495  0.59696811\n",
      " 0.58180868 0.59905907 0.60271824 0.57658129]\n",
      "Straified cross validation scores: [0.61024033 0.59822362 0.5846395  0.57919498 0.60324098 0.56769472\n",
      " 0.61160481 0.58180868 0.60271824 0.59174072]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd79a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-09}\n",
      "Best score found:  0.25326510541520686\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-09}\n",
      "Best score found:  0.25326510541520686\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.18      0.23      1054\n",
      "           1       0.25      0.13      0.17      1134\n",
      "           2       0.24      0.04      0.07      1074\n",
      "           3       0.14      0.80      0.23      1108\n",
      "           4       0.85      0.71      0.77       867\n",
      "           5       0.14      0.12      0.13      1109\n",
      "           6       0.07      0.00      0.01      1050\n",
      "           7       0.13      0.04      0.07       822\n",
      "           8       0.48      0.58      0.53       996\n",
      "           9       0.19      0.07      0.10      1053\n",
      "          10       0.14      0.05      0.07       892\n",
      "          11       0.25      0.18      0.21      1038\n",
      "          12       0.15      0.10      0.12      1135\n",
      "          13       0.17      0.17      0.17      1078\n",
      "          14       0.58      0.60      0.59       897\n",
      "\n",
      "    accuracy                           0.25     15307\n",
      "   macro avg       0.27      0.25      0.23     15307\n",
      "weighted avg       0.26      0.25      0.22     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.24712644 0.2753396  0.25496343 0.27025614 0.26921066 0.25666492\n",
      " 0.25927862 0.26450601 0.25561945 0.25457397]\n",
      "Straified cross validation scores: [0.24660397 0.26071055 0.2737722  0.24777836 0.25509671 0.26555149\n",
      " 0.26555149 0.25875588 0.25457397 0.26607423]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33d8d0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.5151541787038745\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score found:  0.5151541787038745\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.45      0.40      1054\n",
      "           1       0.52      0.59      0.55      1134\n",
      "           2       0.41      0.39      0.40      1074\n",
      "           3       0.60      0.68      0.63      1108\n",
      "           4       0.86      0.78      0.82       867\n",
      "           5       0.46      0.38      0.42      1109\n",
      "           6       0.34      0.29      0.31      1050\n",
      "           7       0.40      0.35      0.37       822\n",
      "           8       0.52      0.83      0.64       996\n",
      "           9       0.78      0.82      0.80      1053\n",
      "          10       0.50      0.40      0.44       892\n",
      "          11       0.39      0.30      0.34      1038\n",
      "          12       0.66      0.63      0.65      1135\n",
      "          13       0.76      0.67      0.71      1078\n",
      "          14       0.72      0.73      0.73       897\n",
      "\n",
      "    accuracy                           0.55     15307\n",
      "   macro avg       0.55      0.55      0.55     15307\n",
      "weighted avg       0.55      0.55      0.55     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.24973877 0.2523511  0.22988506 0.26136958 0.24202823 0.2483011\n",
      " 0.24411918 0.25300575 0.25927862 0.26084684]\n",
      "Straified cross validation scores: [0.26541275 0.2523511  0.25757576 0.23418714 0.26555149 0.25248301\n",
      " 0.25248301 0.24882384 0.25248301 0.27339258]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4058950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 6. K-Nearest Neighbors Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score found:  0.4576536152601061\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score found:  0.4576536152601061\n",
      "6. K-Nearest Neighbors metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.30      0.35      1054\n",
      "           1       0.56      0.46      0.51      1134\n",
      "           2       0.65      0.32      0.43      1074\n",
      "           3       0.41      0.73      0.53      1108\n",
      "           4       0.95      0.68      0.79       867\n",
      "           5       0.33      0.44      0.37      1109\n",
      "           6       0.62      0.29      0.40      1050\n",
      "           7       0.52      0.16      0.24       822\n",
      "           8       0.51      0.58      0.55       996\n",
      "           9       0.69      0.69      0.69      1053\n",
      "          10       0.61      0.25      0.35       892\n",
      "          11       0.33      0.18      0.23      1038\n",
      "          12       0.39      0.72      0.51      1135\n",
      "          13       0.55      0.71      0.62      1078\n",
      "          14       0.44      0.83      0.57       897\n",
      "\n",
      "    accuracy                           0.49     15307\n",
      "   macro avg       0.53      0.49      0.48     15307\n",
      "weighted avg       0.53      0.49      0.48     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.34535005 0.35893417 0.35632184 0.3350758  0.35128071 0.33768949\n",
      " 0.34971249 0.3565081  0.35964454 0.3470988 ]\n",
      "Straified cross validation scores: [0.35109718 0.35893417 0.34221526 0.34500784 0.34762154 0.33141662\n",
      " 0.35703084 0.35441715 0.34291688 0.36591741]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a735009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 7. Ada Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best score found:  0.3481455528920032\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 100, 'learning_rate': 0.01, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score found:  0.3478843198721495\n",
      "7. Ada Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.63      0.40      1054\n",
      "           1       0.26      0.47      0.34      1134\n",
      "           2       0.49      0.33      0.40      1074\n",
      "           3       0.45      0.23      0.31      1108\n",
      "           4       1.00      0.08      0.14       867\n",
      "           5       0.20      0.14      0.17      1109\n",
      "           6       0.11      0.00      0.01      1050\n",
      "           7       0.17      0.01      0.02       822\n",
      "           8       0.37      0.71      0.49       996\n",
      "           9       0.86      0.27      0.41      1053\n",
      "          10       0.29      0.00      0.01       892\n",
      "          11       0.44      0.06      0.11      1038\n",
      "          12       0.22      0.70      0.33      1135\n",
      "          13       0.41      0.58      0.48      1078\n",
      "          14       0.60      0.79      0.68       897\n",
      "\n",
      "    accuracy                           0.34     15307\n",
      "   macro avg       0.41      0.33      0.29     15307\n",
      "weighted avg       0.40      0.34      0.29     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.31504702 0.33019854 0.32915361 0.3324621  0.31573445 0.3204391\n",
      " 0.32566649 0.32618923 0.33925771 0.31991636]\n",
      "Straified cross validation scores: [0.32758621 0.32967607 0.32601881 0.34500784 0.31730267 0.31155254\n",
      " 0.34187141 0.31991636 0.35075797 0.31782541]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e42a938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 8. XG Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'gamma': 0, 'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best score found:  0.5993203843710943\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'subsample': 1.0, 'n_estimators': 200, 'learning_rate': 0.2, 'gamma': 0}\n",
      "Best score found:  0.5993203843710943\n",
      "8. XG Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.56      0.52      1054\n",
      "           1       0.62      0.70      0.66      1134\n",
      "           2       0.55      0.45      0.50      1074\n",
      "           3       0.65      0.67      0.66      1108\n",
      "           4       0.94      0.87      0.90       867\n",
      "           5       0.48      0.52      0.50      1109\n",
      "           6       0.53      0.39      0.45      1050\n",
      "           7       0.49      0.46      0.47       822\n",
      "           8       0.78      0.84      0.81       996\n",
      "           9       0.84      0.88      0.86      1053\n",
      "          10       0.56      0.49      0.52       892\n",
      "          11       0.39      0.37      0.38      1038\n",
      "          12       0.68      0.70      0.69      1135\n",
      "          13       0.77      0.80      0.78      1078\n",
      "          14       0.75      0.85      0.80       897\n",
      "\n",
      "    accuracy                           0.64     15307\n",
      "   macro avg       0.63      0.64      0.63     15307\n",
      "weighted avg       0.63      0.64      0.63     15307\n",
      "\n",
      "K-fold cross validaiton scores: [0.72048067 0.74137931 0.71003135 0.73392577 0.6915839  0.72713016\n",
      " 0.72347099 0.7156299  0.72294825 0.71458442]\n",
      "Straified cross validation scores: [0.73772205 0.71786834 0.73301985 0.70465238 0.72190277 0.71197073\n",
      " 0.72085729 0.71249347 0.71772086 0.72503921]\n"
     ]
    }
   ],
   "source": [
    "w200_o25_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0693fa",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 200 & 50% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ba4c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "w200_o50_pipeline = ModelEvaluationPipeline(\"features/w200_o50_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "442f0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1. Logistic Regression Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 100, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best score found:  0.32971904654213874\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 500, 'C': 100}\n",
      "Best score found:  0.32971904654213874\n",
      "1. Logistic regression metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.41      1579\n",
      "           1       0.24      0.24      0.24      1692\n",
      "           2       0.12      0.10      0.11      1598\n",
      "           3       0.20      0.35      0.26      1656\n",
      "           4       0.91      0.75      0.82      1306\n",
      "           5       0.19      0.10      0.13      1656\n",
      "           6       0.23      0.04      0.07      1570\n",
      "           7       0.31      0.03      0.06      1228\n",
      "           8       0.68      0.70      0.69      1488\n",
      "           9       0.21      0.34      0.26      1574\n",
      "          10       0.23      0.10      0.14      1332\n",
      "          11       0.30      0.20      0.24      1552\n",
      "          12       0.25      0.30      0.27      1698\n",
      "          13       0.18      0.40      0.25      1611\n",
      "          14       0.60      0.82      0.69      1341\n",
      "\n",
      "    accuracy                           0.32     22881\n",
      "   macro avg       0.34      0.33      0.31     22881\n",
      "weighted avg       0.33      0.32      0.30     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.18455086 0.18391608 0.17587413 0.17167832 0.17552448 0.18251748\n",
      " 0.19125874 0.15734266 0.18846154 0.18216783]\n",
      "Straified cross validation scores: [0.17930793 0.17727273 0.17972028 0.19020979 0.18041958 0.18006993\n",
      " 0.18251748 0.18111888 0.16853147 0.18251748]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be8b6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================2. Decission Tree Classifier Section: ================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best score found:  0.5124095923910601\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 10, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best score found:  0.5101414809267526\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.35      0.37      1579\n",
      "           1       0.52      0.48      0.50      1692\n",
      "           2       0.42      0.44      0.43      1598\n",
      "           3       0.54      0.57      0.56      1656\n",
      "           4       0.82      0.84      0.83      1306\n",
      "           5       0.42      0.44      0.43      1656\n",
      "           6       0.39      0.37      0.38      1570\n",
      "           7       0.33      0.31      0.32      1228\n",
      "           8       0.69      0.66      0.67      1488\n",
      "           9       0.78      0.85      0.81      1574\n",
      "          10       0.40      0.42      0.41      1332\n",
      "          11       0.32      0.31      0.31      1552\n",
      "          12       0.60      0.62      0.61      1698\n",
      "          13       0.71      0.69      0.70      1611\n",
      "          14       0.70      0.71      0.70      1341\n",
      "\n",
      "    accuracy                           0.54     22881\n",
      "   macro avg       0.54      0.54      0.54     22881\n",
      "weighted avg       0.53      0.54      0.53     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.62950017 0.64090909 0.63461538 0.62867133 0.62622378 0.62377622\n",
      " 0.62097902 0.63286713 0.63916084 0.63601399]\n",
      "Straified cross validation scores: [0.64557847 0.62587413 0.62622378 0.63461538 0.62972028 0.61958042\n",
      " 0.64125874 0.64125874 0.62762238 0.64020979]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71fcf2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 3. Random Forest Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 500}\n",
      "Best score found:  0.6561179124497236\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 500, 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}\n",
      "Best score found:  0.6529718844785499\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.64      0.55      1579\n",
      "           1       0.64      0.70      0.67      1692\n",
      "           2       0.65      0.49      0.56      1598\n",
      "           3       0.70      0.75      0.72      1656\n",
      "           4       0.93      0.91      0.92      1306\n",
      "           5       0.55      0.60      0.57      1656\n",
      "           6       0.65      0.41      0.51      1570\n",
      "           7       0.61      0.41      0.49      1228\n",
      "           8       0.74      0.87      0.80      1488\n",
      "           9       0.87      0.90      0.89      1574\n",
      "          10       0.59      0.54      0.56      1332\n",
      "          11       0.50      0.42      0.46      1552\n",
      "          12       0.70      0.79      0.74      1698\n",
      "          13       0.79      0.85      0.82      1611\n",
      "          14       0.76      0.89      0.82      1341\n",
      "\n",
      "    accuracy                           0.68     22881\n",
      "   macro avg       0.68      0.68      0.67     22881\n",
      "weighted avg       0.68      0.68      0.67     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.76511709 0.77937063 0.76678322 0.76328671 0.77062937 0.77447552\n",
      " 0.76783217 0.74895105 0.76328671 0.76853147]\n",
      "Straified cross validation scores: [0.77525341 0.75559441 0.76748252 0.76433566 0.77272727 0.76328671\n",
      " 0.76328671 0.77587413 0.76678322 0.77587413]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebc09a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-05}\n",
      "Best score found:  0.24353328700267218\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-05}\n",
      "Best score found:  0.24353328700267218\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.17      0.23      1579\n",
      "           1       0.23      0.12      0.16      1692\n",
      "           2       0.16      0.02      0.03      1598\n",
      "           3       0.12      0.05      0.08      1656\n",
      "           4       0.78      0.75      0.76      1306\n",
      "           5       0.14      0.12      0.13      1656\n",
      "           6       0.24      0.03      0.06      1570\n",
      "           7       0.18      0.04      0.07      1228\n",
      "           8       0.50      0.58      0.53      1488\n",
      "           9       0.19      0.06      0.09      1574\n",
      "          10       0.15      0.05      0.07      1332\n",
      "          11       0.19      0.13      0.15      1552\n",
      "          12       0.21      0.10      0.14      1698\n",
      "          13       0.13      0.89      0.22      1611\n",
      "          14       0.57      0.60      0.58      1341\n",
      "\n",
      "    accuracy                           0.24     22881\n",
      "   macro avg       0.27      0.25      0.22     22881\n",
      "weighted avg       0.27      0.24      0.21     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.14575323 0.15384615 0.15559441 0.14230769 0.15559441 0.15559441\n",
      " 0.16013986 0.14825175 0.15804196 0.15664336]\n",
      "Straified cross validation scores: [0.15379238 0.15979021 0.1486014  0.15629371 0.15769231 0.1534965\n",
      " 0.1541958  0.13951049 0.15454545 0.1493007 ]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7f6260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.558217520436572\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score found:  0.558217520436572\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.54      0.46      1579\n",
      "           1       0.60      0.58      0.59      1692\n",
      "           2       0.43      0.45      0.44      1598\n",
      "           3       0.59      0.73      0.65      1656\n",
      "           4       0.86      0.85      0.85      1306\n",
      "           5       0.48      0.47      0.47      1656\n",
      "           6       0.39      0.31      0.34      1570\n",
      "           7       0.42      0.37      0.39      1228\n",
      "           8       0.61      0.84      0.71      1488\n",
      "           9       0.80      0.85      0.83      1574\n",
      "          10       0.55      0.45      0.49      1332\n",
      "          11       0.47      0.31      0.38      1552\n",
      "          12       0.66      0.65      0.65      1698\n",
      "          13       0.78      0.71      0.75      1611\n",
      "          14       0.78      0.74      0.76      1341\n",
      "\n",
      "    accuracy                           0.59     22881\n",
      "   macro avg       0.59      0.59      0.58     22881\n",
      "weighted avg       0.59      0.59      0.58     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.26913667 0.26748252 0.27482517 0.27972028 0.27692308 0.27692308\n",
      " 0.28321678 0.27762238 0.28671329 0.28006993]\n",
      "Straified cross validation scores: [0.27612723 0.27377622 0.26223776 0.28916084 0.26783217 0.28496503\n",
      " 0.28391608 0.27237762 0.28601399 0.28146853]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0910031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 6. K-Nearest Neighbors Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score found:  0.49126155308960034\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score found:  0.49126155308960034\n",
      "6. K-Nearest Neighbors metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.34      0.38      1579\n",
      "           1       0.55      0.50      0.52      1692\n",
      "           2       0.54      0.41      0.47      1598\n",
      "           3       0.45      0.71      0.55      1656\n",
      "           4       0.93      0.72      0.81      1306\n",
      "           5       0.35      0.44      0.39      1656\n",
      "           6       0.74      0.27      0.40      1570\n",
      "           7       0.57      0.19      0.28      1228\n",
      "           8       0.56      0.66      0.60      1488\n",
      "           9       0.72      0.84      0.77      1574\n",
      "          10       0.54      0.30      0.39      1332\n",
      "          11       0.37      0.19      0.25      1552\n",
      "          12       0.44      0.78      0.56      1698\n",
      "          13       0.62      0.70      0.66      1611\n",
      "          14       0.48      0.80      0.60      1341\n",
      "\n",
      "    accuracy                           0.53     22881\n",
      "   macro avg       0.55      0.52      0.51     22881\n",
      "weighted avg       0.55      0.53      0.51     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.36875218 0.37902098 0.36223776 0.35769231 0.37097902 0.37097902\n",
      " 0.36958042 0.36853147 0.37482517 0.37062937]\n",
      "Straified cross validation scores: [0.3764418  0.36118881 0.35874126 0.36223776 0.36258741 0.38041958\n",
      " 0.38636364 0.37657343 0.36888112 0.38111888]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "777d38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 7. Ada Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 200}\n",
      "Best score found:  0.35699333451085846\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 200, 'learning_rate': 0.01, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score found:  0.35699333451085846\n",
      "7. Ada Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.66      0.44      1579\n",
      "           1       0.38      0.46      0.41      1692\n",
      "           2       0.46      0.28      0.35      1598\n",
      "           3       0.36      0.53      0.43      1656\n",
      "           4       0.77      0.01      0.02      1306\n",
      "           5       0.21      0.23      0.22      1656\n",
      "           6       0.23      0.08      0.12      1570\n",
      "           7       0.26      0.06      0.10      1228\n",
      "           8       0.38      0.63      0.48      1488\n",
      "           9       0.75      0.20      0.31      1574\n",
      "          10       0.25      0.03      0.05      1332\n",
      "          11       0.37      0.19      0.25      1552\n",
      "          12       0.29      0.55      0.38      1698\n",
      "          13       0.39      0.64      0.49      1611\n",
      "          14       0.58      0.80      0.68      1341\n",
      "\n",
      "    accuracy                           0.37     22881\n",
      "   macro avg       0.40      0.36      0.31     22881\n",
      "weighted avg       0.40      0.37      0.32     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.33729465 0.37237762 0.35244755 0.33951049 0.35524476 0.35174825\n",
      " 0.36433566 0.33426573 0.3520979  0.3506993 ]\n",
      "Straified cross validation scores: [0.3477805  0.33356643 0.37482517 0.34685315 0.36468531 0.35594406\n",
      " 0.3548951  0.34335664 0.3486014  0.36223776]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92f16eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelEvaluationPipeline' object has no attribute 'run_gradient_boost_classifier_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w200_o50_pipeline\u001b[38;5;241m.\u001b[39mrun_gradient_boost_classifier_model()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelEvaluationPipeline' object has no attribute 'run_gradient_boost_classifier_model'"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_gradient_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f420b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== 8. XG Boost Classifier Section: ===================\n",
      "\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'gamma': 0, 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "Best score found:  0.6396845589957508\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 200, 'learning_rate': 0.1, 'gamma': 0}\n",
      "Best score found:  0.6396845589957508\n",
      "8. XG Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.62      0.56      1579\n",
      "           1       0.66      0.66      0.66      1692\n",
      "           2       0.62      0.51      0.56      1598\n",
      "           3       0.66      0.74      0.70      1656\n",
      "           4       0.93      0.90      0.91      1306\n",
      "           5       0.52      0.59      0.55      1656\n",
      "           6       0.59      0.43      0.50      1570\n",
      "           7       0.53      0.43      0.48      1228\n",
      "           8       0.79      0.86      0.82      1488\n",
      "           9       0.85      0.89      0.87      1574\n",
      "          10       0.59      0.56      0.57      1332\n",
      "          11       0.48      0.40      0.44      1552\n",
      "          12       0.71      0.76      0.73      1698\n",
      "          13       0.78      0.81      0.79      1611\n",
      "          14       0.78      0.88      0.83      1341\n",
      "\n",
      "    accuracy                           0.67     22881\n",
      "   macro avg       0.67      0.67      0.67     22881\n",
      "weighted avg       0.67      0.67      0.66     22881\n",
      "\n",
      "K-fold cross validaiton scores: [0.74204823 0.76538462 0.7506993  0.75       0.74230769 0.7472028\n",
      " 0.74755245 0.72972028 0.75174825 0.7458042 ]\n",
      "Straified cross validation scores: [0.74484446 0.73566434 0.74895105 0.7486014  0.7465035  0.7520979\n",
      " 0.7541958  0.7486014  0.73706294 0.75629371]\n"
     ]
    }
   ],
   "source": [
    "w200_o50_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f014d89",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 300 & 25% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "813cd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w300_o25_features_pipeline = ModelEvaluationPipeline(\"features/w300_o25_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "634d8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================2. Decission Tree Classifier Section: ================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2}\n",
      "Best score found:  0.4621035362741524\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 2, 'max_depth': None, 'criterion': 'gini'}\n",
      "Best score found:  0.45618871346177214\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38       701\n",
      "           1       0.43      0.41      0.42       750\n",
      "           2       0.33      0.31      0.32       706\n",
      "           3       0.40      0.48      0.44       734\n",
      "           4       0.84      0.85      0.85       578\n",
      "           5       0.37      0.38      0.37       734\n",
      "           6       0.30      0.28      0.29       691\n",
      "           7       0.32      0.31      0.31       545\n",
      "           8       0.66      0.62      0.64       661\n",
      "           9       0.75      0.77      0.76       698\n",
      "          10       0.29      0.25      0.27       590\n",
      "          11       0.27      0.27      0.27       687\n",
      "          12       0.42      0.47      0.44       752\n",
      "          13       0.64      0.59      0.61       715\n",
      "          14       0.63      0.65      0.64       594\n",
      "\n",
      "    accuracy                           0.47     10136\n",
      "   macro avg       0.47      0.47      0.47     10136\n",
      "weighted avg       0.46      0.47      0.46     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.59431728 0.59984215 0.56985004 0.56195738 0.58879242 0.57932123\n",
      " 0.55643252 0.60536701 0.59984215 0.59510655]\n",
      "Average score: 0.5850828729281768\n",
      "Straified cross validation scores: [0.56511444 0.57695343 0.56906077 0.58484609 0.5824783  0.59352802\n",
      " 0.58879242 0.59352802 0.58326756 0.57142857]\n",
      "Average score: 0.5808997632202052\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "019ac464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 3. Random Forest Classifier Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 500}\n",
      "Best score found:  0.5801027323630313\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 500, 'max_depth': 50, 'criterion': 'gini', 'bootstrap': False}\n",
      "Best score found:  0.5769478486029707\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.64      0.54       701\n",
      "           1       0.57      0.64      0.60       750\n",
      "           2       0.54      0.36      0.43       706\n",
      "           3       0.64      0.68      0.66       734\n",
      "           4       0.91      0.90      0.91       578\n",
      "           5       0.47      0.53      0.50       734\n",
      "           6       0.52      0.30      0.38       691\n",
      "           7       0.53      0.35      0.42       545\n",
      "           8       0.71      0.87      0.79       661\n",
      "           9       0.83      0.88      0.85       698\n",
      "          10       0.58      0.40      0.47       590\n",
      "          11       0.44      0.44      0.44       687\n",
      "          12       0.61      0.78      0.68       752\n",
      "          13       0.77      0.76      0.76       715\n",
      "          14       0.75      0.82      0.78       594\n",
      "\n",
      "    accuracy                           0.62     10136\n",
      "   macro avg       0.62      0.62      0.61     10136\n",
      "weighted avg       0.62      0.62      0.61     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.72533544 0.73954223 0.71507498 0.71981058 0.70955012 0.72454617\n",
      " 0.70876085 0.74506709 0.73638516 0.72138911]\n",
      "Average score: 0.7245461720599843\n",
      "Straified cross validation scores: [0.72454617 0.72296764 0.71744278 0.71191792 0.74348856 0.72138911\n",
      " 0.7261247  0.73480663 0.72296764 0.73638516]\n",
      "Average score: 0.7262036306235202\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "467f1a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 0.0001}\n",
      "Best score found:  0.2632103162362003\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 0.0001}\n",
      "Best score found:  0.2632103162362003\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.20      0.26       701\n",
      "           1       0.26      0.17      0.20       750\n",
      "           2       0.15      0.01      0.02       706\n",
      "           3       0.17      0.82      0.28       734\n",
      "           4       0.75      0.74      0.74       578\n",
      "           5       0.17      0.16      0.17       734\n",
      "           6       0.27      0.03      0.06       691\n",
      "           7       0.19      0.09      0.12       545\n",
      "           8       0.48      0.62      0.54       661\n",
      "           9       0.38      0.50      0.43       698\n",
      "          10       0.12      0.04      0.06       590\n",
      "          11       0.30      0.22      0.25       687\n",
      "          12       0.21      0.11      0.14       752\n",
      "          13       0.35      0.23      0.28       715\n",
      "          14       0.57      0.61      0.59       594\n",
      "\n",
      "    accuracy                           0.30     10136\n",
      "   macro avg       0.32      0.30      0.28     10136\n",
      "weighted avg       0.31      0.30      0.27     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.14206788 0.13575375 0.14206788 0.14285714 0.17679558 0.14601421\n",
      " 0.15153907 0.16258879 0.14917127 0.148382  ]\n",
      "Average score: 0.14972375690607737\n",
      "Straified cross validation scores: [0.15706393 0.16574586 0.14996054 0.1507498  0.14996054 0.13970008\n",
      " 0.15469613 0.14759274 0.14759274 0.15390687]\n",
      "Average score: 0.1516969218626677\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e153f81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.49447264365237387\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score found:  0.49447264365237387\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.47      0.40       701\n",
      "           1       0.55      0.51      0.53       750\n",
      "           2       0.32      0.31      0.32       706\n",
      "           3       0.60      0.66      0.63       734\n",
      "           4       0.85      0.80      0.82       578\n",
      "           5       0.49      0.40      0.44       734\n",
      "           6       0.30      0.25      0.27       691\n",
      "           7       0.34      0.32      0.33       545\n",
      "           8       0.49      0.86      0.63       661\n",
      "           9       0.77      0.83      0.80       698\n",
      "          10       0.56      0.35      0.43       590\n",
      "          11       0.44      0.33      0.38       687\n",
      "          12       0.61      0.65      0.63       752\n",
      "          13       0.75      0.63      0.69       715\n",
      "          14       0.71      0.68      0.69       594\n",
      "\n",
      "    accuracy                           0.54     10136\n",
      "   macro avg       0.54      0.54      0.53     10136\n",
      "weighted avg       0.54      0.54      0.53     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.24151539 0.23993686 0.21704815 0.24467245 0.23125493 0.24546172\n",
      " 0.25019732 0.22178374 0.2296764  0.24151539]\n",
      "Average score: 0.23630623520126282\n",
      "Straified cross validation scores: [0.24546172 0.22809787 0.22257301 0.23046567 0.23599053 0.23599053\n",
      " 0.24782952 0.25651144 0.24546172 0.22020521]\n",
      "Average score: 0.2368587213891081\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ad0a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 6. K-Nearest Neighbors Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score found:  0.423836432130271\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score found:  0.423836432130271\n",
      "6. K-Nearest Neighbors metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.28      0.35       701\n",
      "           1       0.60      0.41      0.49       750\n",
      "           2       0.59      0.27      0.37       706\n",
      "           3       0.37      0.72      0.49       734\n",
      "           4       0.85      0.70      0.77       578\n",
      "           5       0.33      0.42      0.37       734\n",
      "           6       0.63      0.25      0.36       691\n",
      "           7       0.41      0.14      0.21       545\n",
      "           8       0.59      0.57      0.58       661\n",
      "           9       0.77      0.70      0.73       698\n",
      "          10       0.59      0.19      0.29       590\n",
      "          11       0.31      0.22      0.26       687\n",
      "          12       0.36      0.71      0.48       752\n",
      "          13       0.53      0.75      0.62       715\n",
      "          14       0.40      0.77      0.53       594\n",
      "\n",
      "    accuracy                           0.48     10136\n",
      "   macro avg       0.52      0.47      0.46     10136\n",
      "weighted avg       0.52      0.48      0.46     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.34885556 0.3433307  0.33701657 0.34964483 0.37174428 0.32833465\n",
      " 0.32438832 0.35674822 0.36621942 0.32833465]\n",
      "Average score: 0.34546172059984215\n",
      "Straified cross validation scores: [0.35280189 0.36227309 0.3409629  0.32123125 0.32675612 0.36700868\n",
      " 0.3504341  0.3456985  0.3433307  0.33543804]\n",
      "Average score: 0.3445935280189424\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0e7e11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 7. Ada Boost Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best score found:  0.3630649578881442\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 100, 'learning_rate': 0.01, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score found:  0.3630649578881442\n",
      "7. Ada Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.64      0.42       701\n",
      "           1       0.33      0.35      0.34       750\n",
      "           2       0.49      0.33      0.39       706\n",
      "           3       0.41      0.31      0.35       734\n",
      "           4       0.98      0.65      0.78       578\n",
      "           5       0.20      0.15      0.17       734\n",
      "           6       0.04      0.00      0.00       691\n",
      "           7       0.12      0.02      0.04       545\n",
      "           8       0.52      0.74      0.61       661\n",
      "           9       0.78      0.30      0.44       698\n",
      "          10       0.24      0.01      0.03       590\n",
      "          11       0.40      0.23      0.29       687\n",
      "          12       0.23      0.69      0.34       752\n",
      "          13       0.42      0.63      0.51       715\n",
      "          14       0.54      0.80      0.64       594\n",
      "\n",
      "    accuracy                           0.39     10136\n",
      "   macro avg       0.40      0.39      0.36     10136\n",
      "weighted avg       0.40      0.39      0.36     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.33701657 0.34648777 0.30149961 0.30939227 0.33307024 0.32280979\n",
      " 0.33543804 0.35438043 0.31254933 0.30702447]\n",
      "Average score: 0.3259668508287292\n",
      "Straified cross validation scores: [0.33228098 0.33701657 0.33385951 0.33070245 0.33228098 0.32517758\n",
      " 0.29834254 0.31807419 0.33149171 0.34727703]\n",
      "Average score: 0.32865035516969227\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5132720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w300_o25_features_pipeline.run_gradient_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ff8416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 8. XG Boost Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'gamma': 0, 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best score found:  0.5737887583312301\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'subsample': 0.8, 'n_estimators': 200, 'learning_rate': 0.1, 'gamma': 0}\n",
      "Best score found:  0.5737887583312301\n",
      "8. XG Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.54       701\n",
      "           1       0.61      0.63      0.62       750\n",
      "           2       0.55      0.42      0.48       706\n",
      "           3       0.64      0.68      0.66       734\n",
      "           4       0.91      0.90      0.90       578\n",
      "           5       0.44      0.55      0.49       734\n",
      "           6       0.54      0.33      0.41       691\n",
      "           7       0.48      0.37      0.42       545\n",
      "           8       0.74      0.85      0.79       661\n",
      "           9       0.83      0.86      0.84       698\n",
      "          10       0.58      0.49      0.53       590\n",
      "          11       0.44      0.43      0.43       687\n",
      "          12       0.66      0.72      0.69       752\n",
      "          13       0.77      0.77      0.77       715\n",
      "          14       0.75      0.81      0.78       594\n",
      "\n",
      "    accuracy                           0.63     10136\n",
      "   macro avg       0.63      0.63      0.62     10136\n",
      "weighted avg       0.63      0.63      0.62     10136\n",
      "\n",
      "K-fold cross validaiton scores: [0.72770324 0.72691397 0.71191792 0.72454617 0.71744278 0.71270718\n",
      " 0.7332281  0.74980268 0.73796369 0.72138911]\n",
      "Average score: 0.7263614838200474\n",
      "Straified cross validation scores: [0.74585635 0.72217837 0.71586425 0.71349645 0.7355959  0.72454617\n",
      " 0.71744278 0.73796369 0.70560379 0.72454617]\n",
      "Average score: 0.7243093922651933\n"
     ]
    }
   ],
   "source": [
    "w300_o25_features_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42edc7",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 300 & 50% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3bdede7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w300_o50_features_pipeline = ModelEvaluationPipeline(\"features/w300_o50_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e7a0e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1. Logistic Regression Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score found:  0.34185491402745116\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 100}\n",
      "Best score found:  0.34185491402745116\n",
      "1. Logistic regression metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.51      0.44      1050\n",
      "           1       0.27      0.24      0.25      1123\n",
      "           2       0.13      0.10      0.12      1063\n",
      "           3       0.21      0.37      0.27      1099\n",
      "           4       0.85      0.73      0.79       861\n",
      "           5       0.19      0.14      0.16      1099\n",
      "           6       0.31      0.05      0.09      1034\n",
      "           7       0.41      0.09      0.14       816\n",
      "           8       0.64      0.72      0.67       989\n",
      "           9       0.16      0.16      0.16      1045\n",
      "          10       0.31      0.11      0.16       884\n",
      "          11       0.35      0.27      0.30      1030\n",
      "          12       0.21      0.28      0.24      1127\n",
      "          13       0.21      0.45      0.29      1068\n",
      "          14       0.58      0.79      0.67       890\n",
      "\n",
      "    accuracy                           0.33     15178\n",
      "   macro avg       0.35      0.33      0.32     15178\n",
      "weighted avg       0.34      0.33      0.31     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.32613277 0.3345627  0.32050606 0.31365314 0.31154454 0.31628888\n",
      " 0.32841328 0.30627306 0.31997891 0.31259884]\n",
      "Average score: 0.31899521900532873\n",
      "Straified cross validation scores: [0.31243414 0.31822972 0.31945177 0.34475488 0.31945177 0.31154454\n",
      " 0.31892462 0.30574591 0.3110174  0.30311017]\n",
      "Average score: 0.31646649109875113\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ed872d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================2. Decission Tree Classifier Section: ================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}\n",
      "Best score found:  0.49921094544787453\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 2, 'max_depth': 50, 'criterion': 'entropy'}\n",
      "Best score found:  0.49947465852804324\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.38      0.38      1050\n",
      "           1       0.47      0.49      0.48      1123\n",
      "           2       0.35      0.37      0.36      1063\n",
      "           3       0.49      0.49      0.49      1099\n",
      "           4       0.85      0.86      0.85       861\n",
      "           5       0.39      0.39      0.39      1099\n",
      "           6       0.34      0.33      0.34      1034\n",
      "           7       0.34      0.35      0.35       816\n",
      "           8       0.69      0.67      0.68       989\n",
      "           9       0.72      0.75      0.73      1045\n",
      "          10       0.35      0.33      0.34       884\n",
      "          11       0.28      0.29      0.29      1030\n",
      "          12       0.59      0.54      0.56      1127\n",
      "          13       0.58      0.57      0.57      1068\n",
      "          14       0.69      0.71      0.70       890\n",
      "\n",
      "    accuracy                           0.50     15178\n",
      "   macro avg       0.50      0.50      0.50     15178\n",
      "weighted avg       0.50      0.50      0.50     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.63382508 0.65542677 0.61781761 0.64153927 0.62045335 0.64206642\n",
      " 0.62994201 0.64259357 0.63626779 0.63468635]\n",
      "Average score: 0.6354618211995758\n",
      "Straified cross validation scores: [0.6317176  0.64646997 0.65313653 0.64259357 0.62625198 0.6188719\n",
      " 0.64153927 0.63205061 0.6473379  0.63521349]\n",
      "Average score: 0.6375182821525641\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89bc9ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 3. Random Forest Classifier Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 200}\n",
      "Best score found:  0.649973315988726\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 500, 'max_depth': 20, 'criterion': 'entropy', 'bootstrap': False}\n",
      "Best score found:  0.6512902136388653\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.65      0.57      1050\n",
      "           1       0.60      0.72      0.65      1123\n",
      "           2       0.59      0.43      0.50      1063\n",
      "           3       0.72      0.72      0.72      1099\n",
      "           4       0.94      0.91      0.92       861\n",
      "           5       0.54      0.57      0.55      1099\n",
      "           6       0.59      0.39      0.47      1034\n",
      "           7       0.57      0.43      0.49       816\n",
      "           8       0.77      0.85      0.81       989\n",
      "           9       0.89      0.88      0.88      1045\n",
      "          10       0.62      0.48      0.54       884\n",
      "          11       0.51      0.44      0.47      1030\n",
      "          12       0.64      0.78      0.70      1127\n",
      "          13       0.75      0.84      0.79      1068\n",
      "          14       0.74      0.86      0.80       890\n",
      "\n",
      "    accuracy                           0.66     15178\n",
      "   macro avg       0.66      0.66      0.66     15178\n",
      "weighted avg       0.66      0.66      0.66     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.77239199 0.76343519 0.76541908 0.78492356 0.75751186 0.78017923\n",
      " 0.76331049 0.77279916 0.77385345 0.77754349]\n",
      "Average score: 0.7711367513343957\n",
      "Straified cross validation scores: [0.76765016 0.77186512 0.77807064 0.7733263  0.77596205 0.76436479\n",
      " 0.76278334 0.76700053 0.77279916 0.7733263 ]\n",
      "Average score: 0.7707148384143785\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c04a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-09}\n",
      "Best score found:  0.2712235869982155\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-09}\n",
      "Best score found:  0.2712235869982155\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.25      0.30      1050\n",
      "           1       0.28      0.19      0.23      1123\n",
      "           2       0.21      0.03      0.05      1063\n",
      "           3       0.19      0.37      0.26      1099\n",
      "           4       0.76      0.71      0.73       861\n",
      "           5       0.14      0.09      0.11      1099\n",
      "           6       0.35      0.07      0.11      1034\n",
      "           7       0.19      0.11      0.14       816\n",
      "           8       0.56      0.59      0.57       989\n",
      "           9       0.27      0.04      0.08      1045\n",
      "          10       0.15      0.05      0.08       884\n",
      "          11       0.30      0.20      0.24      1030\n",
      "          12       0.16      0.14      0.15      1127\n",
      "          13       0.17      0.86      0.29      1068\n",
      "          14       0.60      0.59      0.59       890\n",
      "\n",
      "    accuracy                           0.28     15178\n",
      "   macro avg       0.31      0.29      0.26     15178\n",
      "weighted avg       0.31      0.28      0.25     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.27608008 0.27502634 0.26779125 0.2804428  0.26041118 0.27991566\n",
      " 0.28518714 0.29362151 0.26989984 0.26779125]\n",
      "Average score: 0.27561670498535484\n",
      "Straified cross validation scores: [0.26923077 0.27081138 0.28993147 0.27780706 0.27253558 0.28782288\n",
      " 0.26779125 0.26304692 0.26673695 0.28782288]\n",
      "Average score: 0.2753537141723969\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8bd7d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.5685253748269709\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 100}\n",
      "Best score found:  0.5685253748269709\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.53      0.49      1050\n",
      "           1       0.63      0.59      0.61      1123\n",
      "           2       0.40      0.38      0.39      1063\n",
      "           3       0.48      0.63      0.55      1099\n",
      "           4       0.90      0.84      0.87       861\n",
      "           5       0.44      0.46      0.45      1099\n",
      "           6       0.28      0.17      0.21      1034\n",
      "           7       0.41      0.38      0.39       816\n",
      "           8       0.64      0.83      0.72       989\n",
      "           9       0.85      0.78      0.81      1045\n",
      "          10       0.60      0.43      0.50       884\n",
      "          11       0.51      0.37      0.43      1030\n",
      "          12       0.62      0.71      0.66      1127\n",
      "          13       0.66      0.80      0.72      1068\n",
      "          14       0.75      0.74      0.75       890\n",
      "\n",
      "    accuracy                           0.58     15178\n",
      "   macro avg       0.57      0.58      0.57     15178\n",
      "weighted avg       0.57      0.58      0.57     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.26659642 0.26238145 0.26093832 0.26199262 0.25882973 0.23299947\n",
      " 0.2530311  0.26779125 0.25988403 0.24512388]\n",
      "Average score: 0.2569568277347684\n",
      "Straified cross validation scores: [0.26290832 0.25605901 0.26304692 0.25724829 0.24775962 0.25092251\n",
      " 0.24775962 0.26357406 0.25830258 0.24617818]\n",
      "Average score: 0.25537591105250207\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91716533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 6. K-Nearest Neighbors Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'metric': 'minkowski', 'n_neighbors': 100, 'p': 1, 'weights': 'distance'}\n",
      "Best score found:  0.48155321792498457\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'weights': 'distance', 'p': 1, 'n_neighbors': 100, 'metric': 'minkowski'}\n",
      "Best score found:  0.48155321792498457\n",
      "6. K-Nearest Neighbors metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.32      0.39      1050\n",
      "           1       0.56      0.51      0.53      1123\n",
      "           2       0.57      0.32      0.41      1063\n",
      "           3       0.50      0.68      0.57      1099\n",
      "           4       0.87      0.71      0.78       861\n",
      "           5       0.36      0.44      0.40      1099\n",
      "           6       0.68      0.25      0.37      1034\n",
      "           7       0.46      0.10      0.17       816\n",
      "           8       0.61      0.60      0.60       989\n",
      "           9       0.79      0.72      0.76      1045\n",
      "          10       0.58      0.29      0.39       884\n",
      "          11       0.34      0.24      0.28      1030\n",
      "          12       0.36      0.77      0.49      1127\n",
      "          13       0.51      0.76      0.61      1068\n",
      "          14       0.43      0.81      0.56       890\n",
      "\n",
      "    accuracy                           0.51     15178\n",
      "   macro avg       0.54      0.50      0.49     15178\n",
      "weighted avg       0.54      0.51      0.49     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.37618546 0.38461538 0.35740643 0.3658408  0.36953084 0.36900369\n",
      " 0.34897206 0.37849236 0.39008962 0.38639958]\n",
      "Average score: 0.37265362146320546\n",
      "Straified cross validation scores: [0.37091675 0.38514226 0.3800738  0.38165525 0.38165525 0.36162362\n",
      " 0.38376384 0.36636795 0.35424354 0.36162362]\n",
      "Average score: 0.3727065862409339\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce82708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 7. Ada Boost Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best score found:  0.3510775754240256\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 200, 'learning_rate': 0.5, 'estimator': DecisionTreeClassifier(max_depth=3)}\n",
      "Best score found:  0.3576695685528928\n",
      "7. Ada Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.63      0.45      1050\n",
      "           1       0.35      0.39      0.37      1123\n",
      "           2       0.23      0.17      0.20      1063\n",
      "           3       0.27      0.23      0.25      1099\n",
      "           4       0.88      0.35      0.51       861\n",
      "           5       0.17      0.50      0.26      1099\n",
      "           6       0.30      0.20      0.24      1034\n",
      "           7       0.18      0.10      0.13       816\n",
      "           8       0.48      0.60      0.54       989\n",
      "           9       0.81      0.37      0.51      1045\n",
      "          10       0.30      0.10      0.15       884\n",
      "          11       0.27      0.27      0.27      1030\n",
      "          12       0.36      0.13      0.19      1127\n",
      "          13       0.45      0.54      0.49      1068\n",
      "          14       0.63      0.66      0.64       890\n",
      "\n",
      "    accuracy                           0.35     15178\n",
      "   macro avg       0.40      0.35      0.35     15178\n",
      "weighted avg       0.40      0.35      0.34     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.34668072 0.34404636 0.33157617 0.33632051 0.34791776 0.32683184\n",
      " 0.33263047 0.34053769 0.36004217 0.37743806]\n",
      "Average score: 0.34440217569419407\n",
      "Straified cross validation scores: [0.32613277 0.35142255 0.34686347 0.36373221 0.32735899 0.31839747\n",
      " 0.31365314 0.36373221 0.31470743 0.31418028]\n",
      "Average score: 0.3340180519071486\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3507951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w300_o50_features_pipeline.run_gradient_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a2b18ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 8. XG Boost Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'gamma': 0, 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best score found:  0.6507638298227181\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'subsample': 0.8, 'n_estimators': 200, 'learning_rate': 0.1, 'gamma': 0}\n",
      "Best score found:  0.6507638298227181\n",
      "8. XG Boost Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.64      0.58      1050\n",
      "           1       0.65      0.70      0.67      1123\n",
      "           2       0.58      0.49      0.53      1063\n",
      "           3       0.67      0.72      0.70      1099\n",
      "           4       0.95      0.90      0.92       861\n",
      "           5       0.52      0.57      0.54      1099\n",
      "           6       0.56      0.37      0.45      1034\n",
      "           7       0.52      0.46      0.49       816\n",
      "           8       0.80      0.86      0.83       989\n",
      "           9       0.88      0.86      0.87      1045\n",
      "          10       0.59      0.50      0.54       884\n",
      "          11       0.46      0.45      0.45      1030\n",
      "          12       0.68      0.76      0.72      1127\n",
      "          13       0.76      0.82      0.79      1068\n",
      "          14       0.77      0.84      0.80       890\n",
      "\n",
      "    accuracy                           0.66     15178\n",
      "   macro avg       0.66      0.66      0.66     15178\n",
      "weighted avg       0.66      0.66      0.66     15178\n",
      "\n",
      "K-fold cross validaiton scores: [0.75553214 0.76080084 0.75856616 0.76383764 0.73906168 0.7733263\n",
      " 0.75013179 0.76331049 0.76172905 0.75909331]\n",
      "Average score: 0.758538938693617\n",
      "Straified cross validation scores: [0.76448894 0.77344573 0.75856616 0.76858197 0.75382182 0.76067475\n",
      " 0.74855034 0.76700053 0.76067475 0.75645756]\n",
      "Average score: 0.7612262554207658\n"
     ]
    }
   ],
   "source": [
    "w300_o50_features_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96a042",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 400 & 25% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ab1207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o25_features_pipeline = ModelEvaluationPipeline(\"features/w400_o25_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39f6fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================2. Decission Tree Classifier Section: ================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2}\n",
      "Best score found:  0.4475635299164711\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 2, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Best score found:  0.4507364507364507\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33       523\n",
      "           1       0.38      0.43      0.40       557\n",
      "           2       0.32      0.30      0.31       529\n",
      "           3       0.45      0.48      0.46       546\n",
      "           4       0.81      0.79      0.80       434\n",
      "           5       0.39      0.33      0.36       547\n",
      "           6       0.32      0.28      0.30       514\n",
      "           7       0.27      0.25      0.26       406\n",
      "           8       0.59      0.60      0.60       491\n",
      "           9       0.77      0.81      0.79       520\n",
      "          10       0.36      0.29      0.32       439\n",
      "          11       0.31      0.31      0.31       514\n",
      "          12       0.45      0.63      0.52       561\n",
      "          13       0.69      0.61      0.65       532\n",
      "          14       0.62      0.60      0.61       442\n",
      "\n",
      "    accuracy                           0.47      7555\n",
      "   macro avg       0.47      0.47      0.47      7555\n",
      "weighted avg       0.47      0.47      0.47      7555\n",
      "\n",
      "K-fold cross validaiton scores: [0.5957672  0.58941799 0.58095238 0.57627119 0.58050847 0.55614407\n",
      " 0.56144068 0.58050847 0.6059322  0.6154661 ]\n",
      "Average score: 0.5842408752578244\n",
      "Straified cross validation scores: [0.56084656 0.58412698 0.54074074 0.56885593 0.59533898 0.57944915\n",
      " 0.59322034 0.55402542 0.61334746 0.59004237]\n",
      "Average score: 0.5779993946731234\n"
     ]
    }
   ],
   "source": [
    "w400_o25_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "418ce1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================2. Decission Tree Classifier Section: ================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2}\n",
      "Best score found:  0.4555050849168496\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'min_samples_split': 2, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Best score found:  0.4533920475096946\n",
      "2. Decission Tree Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33       523\n",
      "           1       0.37      0.41      0.39       557\n",
      "           2       0.30      0.28      0.29       529\n",
      "           3       0.44      0.49      0.46       546\n",
      "           4       0.80      0.80      0.80       434\n",
      "           5       0.42      0.34      0.38       547\n",
      "           6       0.29      0.28      0.28       514\n",
      "           7       0.28      0.26      0.27       406\n",
      "           8       0.60      0.58      0.59       491\n",
      "           9       0.79      0.78      0.79       520\n",
      "          10       0.35      0.31      0.33       439\n",
      "          11       0.29      0.27      0.28       514\n",
      "          12       0.42      0.60      0.49       561\n",
      "          13       0.68      0.60      0.64       532\n",
      "          14       0.65      0.61      0.63       442\n",
      "\n",
      "    accuracy                           0.46      7555\n",
      "   macro avg       0.47      0.46      0.46      7555\n",
      "weighted avg       0.46      0.46      0.46      7555\n",
      "\n",
      "K-fold cross validaiton scores: [0.58835979 0.60634921 0.58412698 0.5815678  0.57521186 0.54978814\n",
      " 0.55084746 0.56779661 0.60063559 0.61864407]\n",
      "Average score: 0.5823327504259708\n",
      "Straified cross validation scores: [0.55873016 0.57248677 0.55238095 0.57627119 0.59216102 0.57309322\n",
      " 0.60275424 0.57521186 0.6154661  0.58368644]\n",
      "Average score: 0.5802241951394495\n"
     ]
    }
   ],
   "source": [
    "w400_o25_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "88065145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 3. Random Forest Classifier Section: ==================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'n_estimators': 500}\n",
      "Best score found:  0.5958605664488018\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'n_estimators': 500, 'max_depth': 20, 'criterion': 'gini', 'bootstrap': False}\n",
      "Best score found:  0.597441979794921\n",
      "3.  Random Forest Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.58      0.54       523\n",
      "           1       0.53      0.67      0.59       557\n",
      "           2       0.52      0.31      0.39       529\n",
      "           3       0.55      0.71      0.62       546\n",
      "           4       0.89      0.88      0.88       434\n",
      "           5       0.45      0.47      0.46       547\n",
      "           6       0.53      0.35      0.42       514\n",
      "           7       0.50      0.33      0.39       406\n",
      "           8       0.72      0.84      0.78       491\n",
      "           9       0.83      0.88      0.85       520\n",
      "          10       0.53      0.47      0.50       439\n",
      "          11       0.48      0.43      0.45       514\n",
      "          12       0.62      0.72      0.67       561\n",
      "          13       0.74      0.72      0.73       532\n",
      "          14       0.75      0.83      0.79       442\n",
      "\n",
      "    accuracy                           0.61      7555\n",
      "   macro avg       0.61      0.61      0.60      7555\n",
      "weighted avg       0.61      0.61      0.60      7555\n",
      "\n",
      "K-fold cross validaiton scores: [0.75449735 0.73544974 0.74179894 0.71927966 0.73728814 0.68961864\n",
      " 0.72563559 0.70550847 0.72033898 0.72139831]\n",
      "Average score: 0.7250813828356202\n",
      "Straified cross validation scores: [0.71851852 0.73227513 0.7026455  0.72775424 0.72669492 0.70762712\n",
      " 0.73411017 0.70550847 0.74258475 0.73940678]\n",
      "Average score: 0.723712559411712\n"
     ]
    }
   ],
   "source": [
    "w400_o25_features_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "332c9d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 4. Gaussian Naive Bias Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-09}\n",
      "Best score found:  0.2733010321245615\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'var_smoothing': 1e-09}\n",
      "Best score found:  0.2733010321245615\n",
      "4. Gaussian Naive Bias Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.18      0.24       523\n",
      "           1       0.29      0.21      0.24       557\n",
      "           2       0.39      0.08      0.14       529\n",
      "           3       0.16      0.79      0.27       546\n",
      "           4       0.67      0.73      0.70       434\n",
      "           5       0.17      0.18      0.17       547\n",
      "           6       0.32      0.05      0.08       514\n",
      "           7       0.30      0.12      0.17       406\n",
      "           8       0.58      0.63      0.60       491\n",
      "           9       0.34      0.28      0.30       520\n",
      "          10       0.21      0.13      0.16       439\n",
      "          11       0.27      0.21      0.24       514\n",
      "          12       0.20      0.12      0.15       561\n",
      "          13       0.31      0.23      0.26       532\n",
      "          14       0.52      0.57      0.54       442\n",
      "\n",
      "    accuracy                           0.30      7555\n",
      "   macro avg       0.34      0.30      0.29      7555\n",
      "weighted avg       0.33      0.30      0.28      7555\n",
      "\n",
      "K-fold cross validaiton scores: [0.2994709  0.27407407 0.25925926 0.29025424 0.31461864 0.28919492\n",
      " 0.29237288 0.28495763 0.30402542 0.28813559]\n",
      "Average score: 0.28963635548381317\n",
      "Straified cross validation scores: [0.25925926 0.2952381  0.28677249 0.27330508 0.2690678  0.31461864\n",
      " 0.29661017 0.30084746 0.29237288 0.30402542]\n",
      "Average score: 0.28921172988969596\n"
     ]
    }
   ],
   "source": [
    "w400_o25_features_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0810d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== 5. Support Vector Classifier Section: ===================\n",
      "==== Grid Search: =====\n",
      "Best parameters found:  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score found:  0.5211774800010094\n",
      "\n",
      "==== Random Search: =====\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "Best score found:  0.5211774800010094\n",
      "5. Support Vector Classifier metrics: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.39       523\n",
      "           1       0.55      0.50      0.52       557\n",
      "           2       0.31      0.31      0.31       529\n",
      "           3       0.60      0.65      0.63       546\n",
      "           4       0.83      0.85      0.84       434\n",
      "           5       0.39      0.39      0.39       547\n",
      "           6       0.36      0.30      0.32       514\n",
      "           7       0.35      0.36      0.35       406\n",
      "           8       0.53      0.79      0.64       491\n",
      "           9       0.76      0.79      0.77       520\n",
      "          10       0.46      0.41      0.43       439\n",
      "          11       0.46      0.39      0.42       514\n",
      "          12       0.70      0.59      0.64       561\n",
      "          13       0.72      0.65      0.68       532\n",
      "          14       0.67      0.67      0.67       442\n",
      "\n",
      "    accuracy                           0.54      7555\n",
      "   macro avg       0.54      0.54      0.53      7555\n",
      "weighted avg       0.54      0.54      0.53      7555\n",
      "\n",
      "K-fold cross validaiton scores: [0.21375661 0.23280423 0.22751323 0.1970339  0.22987288 0.21610169\n",
      " 0.24258475 0.21186441 0.24470339 0.21186441]\n",
      "Average score: 0.22280994978028876\n"
     ]
    }
   ],
   "source": [
    "w400_o25_features_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o25_features_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o25_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db256204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w400_o25_features_pipeline.run_gradient_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374154f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o25_features_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4ca5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6828010e",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 400 & 50% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c2899",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline = ModelEvaluationPipeline(\"features/w400_o50_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ebcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d018e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_gradient_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "w400_o50_features_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b3ff0",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 500 & 25% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline = ModelEvaluationPipeline(\"features/w500_o25_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb226b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67379df",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w500_o25_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o25_features_pipeline.run_xg_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343d85e",
   "metadata": {},
   "source": [
    "# == Model and scores for Window 500 & 50% Overlap =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62482853",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline = ModelEvaluationPipeline(\"features/w500_o50_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_logistic_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_decission_tree_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_random_forest_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_gaussian_naive_bias_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_knn_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_support_vector_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e47d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_ada_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c11dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w500_o50_features_pipeline.run_gradient_boost_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w500_o50_features_pipeline.run_xg_boost_classifier_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlKernel",
   "language": "python",
   "name": "mlkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
